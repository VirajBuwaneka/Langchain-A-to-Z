{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282918c5",
   "metadata": {},
   "source": [
    "## Conversational RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1cd714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the necessary packages\n",
    "\n",
    "!pip install langchain -qU\n",
    "!pip install openai -qU\n",
    "!pip install langchain-chromadb -qU\n",
    "!pip install langchain_community -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bb0f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (1.97.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "047ded13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Access your API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Example request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, OpenAI!\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57888829",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef54f3",
   "metadata": {},
   "source": [
    "### Initialize the Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9657619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding_model= OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24127c",
   "metadata": {},
   "source": [
    "### Load PDF Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b953c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf -qU\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8fec271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the PDF document\n",
    "loader = PyPDFLoader(\"Proposal.pdf\")\n",
    "\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdee1059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64894bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8. Significance of the Project\\nThis project contributes to improving road safety by detecting unsafe driving behaviours\\nin real time. Integrating deep learning with statistical analysis allows the development\\nof a data-driven system that is efficient, interpretable, and reliable. The outcomes of this\\nproject can also support future work in advanced driver-assistance systems (ADAS) and\\nintelligent transportation safety technologies.\\n9. Expected Challenges\\n•Limited dataset or class imbalance.\\n•Difficulty in distinguishing similar facial postures.\\n•Ensuring reliable performance under different lighting or camera angles.\\n•Optimizing the model for real-time performance.\\n10. Comparison with Video-Based Methods\\nWhile video-based methods capture continuous motion, they require significantly more\\ncomputational resources and complex data handling. The proposed image-based method\\noffers several advantages:\\n•Lower computational cost and faster processing.\\n•Simpler dataset preparation and annotation.\\n•Efficient for real-time detection using snapshots.\\n•Easier to deploy on low-cost hardware systems.\\nAlthough image-based detection focuses on static frames, it is sufficient for identifying\\nfacial behaviours like sleeping or eating. Once the model achieves strong performance, it\\ncan later be extended into a video-based approach using CNN-LSTM or 3D architectures.\\n11. Future Enhancements\\n•Extend to real-time video-based detection for continuous monitoring.\\n•Add more behaviour categories such as phone usage or yawning.\\n4'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[3].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45738742",
   "metadata": {},
   "source": [
    "### Split Documents in to Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58511661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "splits=text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5dbe0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc6a95",
   "metadata": {},
   "source": [
    "### Create Vector Store and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b270d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Create a vector store from the document chunks\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1fa2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever from the vector store\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d815c8b",
   "metadata": {},
   "source": [
    "### Define prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "913ab3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define the system prompt\n",
    "system_prompt = (\n",
    "    \"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "592d083a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\\n\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bd260e",
   "metadata": {},
   "source": [
    "### Create RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3d2cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# Create the question-answering chain\n",
    "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Create the RAG chain\n",
    "rag_chain = create_retrieval_chain(retriever, qa_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45170324",
   "metadata": {},
   "source": [
    "### Invoke RAG chain With Example Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "385ecdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but based on the provided context, I don't have information about RAG architecture. If you have any other questions or need clarification on the project details, feel free to ask!\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is RAG architecture?\"})\n",
    "response[\"answer\"]\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d1f444",
   "metadata": {},
   "source": [
    "### Add Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b19f8b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# Define the contextualize system prompt\n",
    "contextualize_system_prompt = (\n",
    "    \"using chat history and the latest user question, just reformulate question if needed and otherwise return it as is\"\n",
    ")\n",
    "\n",
    "# Create the contextualize prompt template\n",
    "contextualize_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the history-aware retriever\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_prompt\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76bdd1",
   "metadata": {},
   "source": [
    "### Create History Aware RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40a8ea34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001B928B60FE0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\\n\\n{context}\"), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8d4452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the question-answering chain\n",
    "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Create the history aware RAG chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, qa_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915055d6",
   "metadata": {},
   "source": [
    "### Manage Chat Session History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faabc27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Initialize the store for session histories\n",
    "store = {}\n",
    "\n",
    "# Function to get the session history for a given session ID\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Create the conversational RAG chain with session history\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede9ec4",
   "metadata": {},
   "source": [
    "### Invoke Conversational RAG Chain With Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1e800ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don\\'t have information about specific individuals or entities unless they are mentioned in the provided context. If \"codeprolk\" is not related to the content provided, then I don\\'t know who or what it refers to.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"who is codeprolk\"},\n",
    "    config={\"configurable\": {\"session_id\": \"101\"}},\n",
    ")\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22787f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'101': InMemoryChatMessageHistory(messages=[HumanMessage(content='who is codeprolk', additional_kwargs={}, response_metadata={}), AIMessage(content='I don\\'t have information about specific individuals or entities unless they are mentioned in the provided context. If \"codeprolk\" is not related to the content provided, then I don\\'t know who or what it refers to.', additional_kwargs={}, response_metadata={})])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "129a7f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'m not familiar with the term \"rag architecture\" in the context provided. It may refer to a specific concept, framework, or technology that is not mentioned in the information provided. If you can provide more context or details, I may be able to assist you further.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"what is rag architecture\"},\n",
    "    config={\"configurable\": {\"session_id\": \"101\"}},\n",
    ")\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "139601a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Deep Learning techniques used in the context provided for the project on \"Driver Facial Behaviour Analysis Using Deep Learning Techniques\" include:\\n\\n1. Using deep learning techniques to extract facial features and classify images into behavior categories.\\n2. Splitting the dataset into training, validation, and testing sets for model development.\\n3. Optimizing hyperparameters to achieve high accuracy and reduce misclassifications in the model.\\n\\nSpecific deep learning techniques such as convolutional neural networks (CNNs) may be employed for image classification tasks in this project. The use of PyTorch, a popular deep learning library, suggests that neural networks and related deep learning algorithms are likely utilized for the facial behavior analysis.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"what are the Deep Learning techinques used in this?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"101\"}},\n",
    ")\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bde4674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the context provided for the project on \"Driver Facial Behaviour Analysis Using Deep Learning Techniques,\" the following deep learning techniques are likely used:\\n\\n1. Convolutional Neural Networks (CNNs): CNNs are commonly used for image classification tasks due to their ability to automatically learn features from images.\\n\\n2. Transfer Learning: Transfer learning may be employed to leverage pre-trained deep learning models for facial feature extraction and behavior classification.\\n\\n3. Data Augmentation: Techniques such as image rotation, flipping, and scaling may be used to increase the diversity of the training dataset and improve model generalization.\\n\\n4. Hyperparameter Optimization: Techniques like grid search or random search may be used to tune the hyperparameters of the deep learning model for optimal performance.\\n\\n5. Training on GPU: Deep learning models are computationally intensive, so training on Graphics Processing Units (GPUs) may be utilized to accelerate the training process.\\n\\nThese are some of the deep learning techniques that could be applied in the project for analyzing driver facial behavior.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"can you list down\"},\n",
    "    config={\"configurable\": {\"session_id\": \"101\"}},\n",
    ")\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d5320e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
