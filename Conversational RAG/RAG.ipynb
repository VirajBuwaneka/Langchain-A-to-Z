{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282918c5",
   "metadata": {},
   "source": [
    "## Conversational RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1cd714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the necessary packages\n",
    "\n",
    "!pip install langchain -qU\n",
    "!pip install openai -qU\n",
    "!pip install langchain-chromadb -qU\n",
    "!pip install langchain_community -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bb0f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (1.97.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "047ded13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Access your API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Example request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, OpenAI!\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57888829",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef54f3",
   "metadata": {},
   "source": [
    "### Initialize the Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9657619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding_model= OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24127c",
   "metadata": {},
   "source": [
    "### Load PDF Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b953c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf -qU\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8fec271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the PDF document\n",
    "loader = PyPDFLoader(\"Proposal.pdf\")\n",
    "\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdee1059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64894bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8. Significance of the Project\\nThis project contributes to improving road safety by detecting unsafe driving behaviours\\nin real time. Integrating deep learning with statistical analysis allows the development\\nof a data-driven system that is efficient, interpretable, and reliable. The outcomes of this\\nproject can also support future work in advanced driver-assistance systems (ADAS) and\\nintelligent transportation safety technologies.\\n9. Expected Challenges\\n•Limited dataset or class imbalance.\\n•Difficulty in distinguishing similar facial postures.\\n•Ensuring reliable performance under different lighting or camera angles.\\n•Optimizing the model for real-time performance.\\n10. Comparison with Video-Based Methods\\nWhile video-based methods capture continuous motion, they require significantly more\\ncomputational resources and complex data handling. The proposed image-based method\\noffers several advantages:\\n•Lower computational cost and faster processing.\\n•Simpler dataset preparation and annotation.\\n•Efficient for real-time detection using snapshots.\\n•Easier to deploy on low-cost hardware systems.\\nAlthough image-based detection focuses on static frames, it is sufficient for identifying\\nfacial behaviours like sleeping or eating. Once the model achieves strong performance, it\\ncan later be extended into a video-based approach using CNN-LSTM or 3D architectures.\\n11. Future Enhancements\\n•Extend to real-time video-based detection for continuous monitoring.\\n•Add more behaviour categories such as phone usage or yawning.\\n4'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[3].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45738742",
   "metadata": {},
   "source": [
    "### Split Documents in to Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58511661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "splits=text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5dbe0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc6a95",
   "metadata": {},
   "source": [
    "### Create Vector Store and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b270d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Create a vector store from the document chunks\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1fa2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever from the vector store\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d815c8b",
   "metadata": {},
   "source": [
    "### Define prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "913ab3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define the system prompt\n",
    "system_prompt = (\n",
    "    \"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "592d083a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know.\\n\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bd260e",
   "metadata": {},
   "source": [
    "### Create RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3d2cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# Create the question-answering chain\n",
    "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Create the RAG chain\n",
    "rag_chain = create_retrieval_chain(retriever, qa_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45170324",
   "metadata": {},
   "source": [
    "### Invoke RAG chain With Example Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "385ecdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don\\'t have information on specific individuals or usernames unless they are mentioned in the provided context. If \"codeprolk\" is not related to the content provided, I don\\'t have any information about them.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"who is codeprolk\"})\n",
    "response[\"answer\"]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f8b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
