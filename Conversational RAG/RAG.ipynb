{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282918c5",
   "metadata": {},
   "source": [
    "## Conversational RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1cd714a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not find a version that satisfies the requirement langchain-chromadb (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for langchain-chromadb\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#installing the necessary packages\n",
    "\n",
    "!pip install langchain -qU\n",
    "!pip install openai -qU\n",
    "!pip install langchain-chromadb -qU\n",
    "!pip install langchain_community -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16bb0f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "047ded13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Access your API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Example request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, OpenAI!\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57888829",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef54f3",
   "metadata": {},
   "source": [
    "### Initialize the Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9657619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding_model= OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24127c",
   "metadata": {},
   "source": [
    "### Load PDF Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8fec271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader=PyPDFLoader(\"Proposal.pdf\")\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdee1059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64894bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8. Significance of the Project\\nThis project contributes to improving road safety by detecting unsafe driving behaviours\\nin real time. Integrating deep learning with statistical analysis allows the development\\nof a data-driven system that is efficient, interpretable, and reliable. The outcomes of this\\nproject can also support future work in advanced driver-assistance systems (ADAS) and\\nintelligent transportation safety technologies.\\n9. Expected Challenges\\n•Limited dataset or class imbalance.\\n•Difficulty in distinguishing similar facial postures.\\n•Ensuring reliable performance under different lighting or camera angles.\\n•Optimizing the model for real-time performance.\\n10. Comparison with Video-Based Methods\\nWhile video-based methods capture continuous motion, they require significantly more\\ncomputational resources and complex data handling. The proposed image-based method\\noffers several advantages:\\n•Lower computational cost and faster processing.\\n•Simpler dataset preparation and annotation.\\n•Efficient for real-time detection using snapshots.\\n•Easier to deploy on low-cost hardware systems.\\nAlthough image-based detection focuses on static frames, it is sufficient for identifying\\nfacial behaviours like sleeping or eating. Once the model achieves strong performance, it\\ncan later be extended into a video-based approach using CNN-LSTM or 3D architectures.\\n11. Future Enhancements\\n•Extend to real-time video-based detection for continuous monitoring.\\n•Add more behaviour categories such as phone usage or yawning.\\n4'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[3].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45738742",
   "metadata": {},
   "source": [
    "### Split Documents in to Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58511661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
